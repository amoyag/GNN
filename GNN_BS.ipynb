{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amoyag/GNN/blob/main/GNN_BS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A GNN toy model\n",
        "A Graph Neural Network (GNN) model that's educational and suitable for a systems biology workshop. It's designed to analyze biological networks like protein-protein interactions or metabolic pathways. It uses PyTorch Geometric:\n",
        "\n",
        "1. The `BiologyGNN` class is a simple GNN with:\n",
        "   - 3 graph convolutional layers\n",
        "   - ReLU activation functions\n",
        "   - Dropout for regularization\n",
        "   - A final linear layer for classification\n",
        "\n",
        "2. Helper functions include:\n",
        "   - `create_example_dataset()`: Creates a sample biological network\n",
        "   - `train_model()`: Handles the training loop\n",
        "\n"
      ],
      "metadata": {
        "id": "LTJJadK-VZlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check PyTorch and CUDA versions\n",
        "\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")"
      ],
      "metadata": {
        "id": "7bYTdJ_sWxh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# use those exact versions in the installation\n",
        "!pip install torch-geometric pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
        "\n",
        "# check the installation\n",
        "import torch_geometric\n",
        "print(f\"PyG version: {torch_geometric.__version__}\")"
      ],
      "metadata": {
        "id": "trZep8DXWpUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install other stuff\n",
        "!pip install  bravado pandas numpy networkx"
      ],
      "metadata": {
        "id": "whcVpQKd9Vt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI0AKugdVUfq"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Add this at the start of your main code\n",
        "set_seed(42)  # or any other number\n",
        "\n",
        "class BiologyGNN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes, hidden_channels=64):\n",
        "        super(BiologyGNN, self).__init__()\n",
        "\n",
        "        # Graph Convolutional layers\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Output layer\n",
        "        self.linear = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First Graph Convolution Layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        # Second Graph Convolution Layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.1, training=self.training)\n",
        "\n",
        "        # Third Graph Convolution Layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Output Layer\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def create_example_dataset():\n",
        "    \"\"\"Create a simple example biological network dataset\"\"\"\n",
        "    # Create a random graph\n",
        "    G = nx.random_geometric_graph(20, 0.3)\n",
        "\n",
        "    # Convert to edge index format\n",
        "    edge_index = torch.tensor([[e[0] for e in G.edges()],\n",
        "                             [e[1] for e in G.edges()]], dtype=torch.long)\n",
        "\n",
        "    # Create random node features (could represent gene expression, protein properties, etc.)\n",
        "    num_node_features = 10\n",
        "    x = torch.randn((20, num_node_features))\n",
        "\n",
        "    # Create random node labels (could represent protein function, pathway membership, etc.)\n",
        "    y = torch.randint(0, 3, (20,))\n",
        "\n",
        "    # Create PyG Data object\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    return data\n",
        "\n",
        "def train_model(model, data, epochs=100):\n",
        "    \"\"\"Train the GNN model\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "#### Evaluate the model\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model, data):\n",
        "    \"\"\"Evaluate model performance with multiple metrics\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Get predictions\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        true = data.y\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(true, pred) * 100\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(true, pred, average=None)\n",
        "        conf_matrix = confusion_matrix(true, pred)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Class')\n",
        "        plt.ylabel('True Class')\n",
        "        plt.show()\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nModel Performance:\")\n",
        "        print(f\"Overall Accuracy: {accuracy:.1f}%\")\n",
        "        for i in range(len(precision)):\n",
        "            print(f\"\\nClass {i}:\")\n",
        "            print(f\"Precision: {precision[i]*100:.1f}%\")\n",
        "            print(f\"Recall: {recall[i]*100:.1f}%\")\n",
        "            print(f\"F1 Score: {f1[i]*100:.1f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create example dataset\n",
        "    data = create_example_dataset()\n",
        "\n",
        "    # Initialize model\n",
        "    model = BiologyGNN(num_node_features=10, num_classes=3)\n",
        "\n",
        "    # Train model\n",
        "    train_model(model, data)\n",
        "\n",
        "    # Make predictions\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index)\n",
        "    predicted_classes = pred.argmax(dim=1)\n",
        "    print(\"\\nPredicted classes:\", predicted_classes)"
      ],
      "metadata": {
        "id": "bl6_4tkIdGpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break down of the results:\n",
        "\n",
        "\n",
        "1. The Loss Values (Epoch lines):\n",
        "  - These show how well the model is learning over time (epochs). Loss starts high and decreases, which means means better performance. It shows the model is learning successfully\n",
        "\n",
        "  Loss is a measure of how wrong the model's predictions are. Think of it as the \"error score\" - the lower the loss, the better the model is performing.\n",
        "\n",
        "  The code\n",
        "  ```python\n",
        "  loss = F.nll_loss(out, data.y)\n",
        "```\n",
        "  tells the system to: make predictions (`out`). We compare these predictions to the true labels (`data.y`). The loss function calculates how far off our predictions are This loss value guides the model in adjusting its parameters to make better predictions.\n",
        "\n",
        "  \n",
        "  Think of training a neural network like teaching someone to play a pattern recognition game. In our case, the model is trying to guess which category (0, 1, or 2) each node in the network belongs to. Every time it makes a guess, it gets feedback in the form of a loss value —essentially a score of how many mistakes it made. The model then uses this feedback to adjust its strategy and make better guesses next time, with a lower loss value indicating fewer mistakes.\n",
        "\n",
        "In the context of biological networks, this becomes particularly meaningful. For instance, the model might be trying to predict whether specific proteins are involved in cancer (class 0) or not (class 1). The loss value would indicate how accurate these predictions are, with a theoretical perfect score of 0 meaning the model correctly identified every protein's role. However, achieving such perfect prediction is rarely possible in practice due to the complexity of biological systems and the inherent noise in biological data.\n",
        "\n",
        "2. The Predicted Classes:\n",
        "  ```\n",
        "  tensor([0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 0, 1, 0, 0, 0, 0, 1])\n",
        "  ```\n",
        "  This shows the model's predictions for each of the 20 nodes (proteins/genes) in your example network, where:\n",
        "  - Each number (0, 1, or 2) represents a different class\n",
        "  - In this example, these are random classes since we used `create_example_dataset()`\n",
        "  - In a real biological context, these could represent:\n",
        "    - Protein functions\n",
        "    - Pathway membership\n",
        "    - Disease association\n",
        "    - Any other categorical property you're trying to predict\n",
        "\n",
        "  However, it's important to note that this is using synthetic data where:\n",
        "  - The network structure is random (from `nx.random_geometric_graph`)\n",
        "  - The node features are random (from `torch.randn`)\n",
        "  - The true labels are random (from `torch.randint`)"
      ],
      "metadata": {
        "id": "dwxekvEnYthm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the model and the data\n",
        "The Graph Neural Network (GNN) used here is designed to learn patterns from network-structured biological data. The model architecture consists of three graph convolutional layers (GCNConv) followed by a final linear layer. Each convolutional layer learns to aggregate information from neighboring nodes, meaning each protein learns from the proteins it interacts with. After each convolution, the model applies a ReLU activation function and dropout (with probability 0.1) to prevent overfitting. The final linear layer maps the learned representations to class probabilities using softmax, effectively making predictions about which category each protein belongs to.\n",
        "\n",
        "The data structure represents a simplified biological network with 20 nodes (proteins) connected randomly using NetworkX's geometric graph generator. Each protein in this network has 10 random features (data.x), which in a real biological context could represent properties like expression levels, molecular weight, or sequence characteristics. The connections between proteins (edges) are established with a proximity threshold of 0.3, meaning proteins are connected if they're within this geometric distance of each other. Each protein is also randomly assigned one of three classes (0, 1, or 2; data.y), simulating a classification task like predicting protein function or disease association. While this synthetic data helps demonstrate how the model works, in a real application you'd replace these random elements with actual protein interaction data, meaningful biological features, and known functional annotations."
      ],
      "metadata": {
        "id": "nT9-wZWOhW-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About training the GNN\n",
        "\n",
        "Think of the ground truth classes (data.y) as labels we already know, like having a set of proteins where we know their functions (some are enzymes, some are transporters, etc.). The model doesn't use these labels to make its predictions - instead, it uses two other pieces of information: the protein features (data.x) and who interacts with whom (edge_index).\n",
        "\n",
        "When making a prediction, the model looks at each protein and considers:\n",
        "1. The protein's own features (like its molecular weight, sequence properties, etc.)\n",
        "2. The features of proteins it's connected to in the network (its interaction partners)\n",
        "\n",
        "Through the training process, the model learns patterns like \"proteins with these features that interact with these types of partners tend to be class 1.\" It's similar to how biologists might infer a protein's function by looking at its properties and what other proteins it interacts with. The model is essentially trying to rediscover the relationship between these patterns and the known classes.\n",
        "\n",
        "Then we compare the model's predictions to those ground truth labels to see how well it learned these patterns. This is where the loss comes in —it measures how different the predictions are from the real classes we knew all along."
      ],
      "metadata": {
        "id": "kDkMUnv7i22b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model evaluation\n",
        "#Use this with your existing model and data\n",
        "evaluate_model(model, data)"
      ],
      "metadata": {
        "id": "LJBO-udwYwc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the evaluation parmeters\n",
        "\n",
        "\n",
        "**Accuracy** is the most straightforward metric - it's simply the percentage of proteins that the model classified correctly. However, accuracy alone can be misleading, especially if the classes are imbalanced (like having many more proteins of one class than others).\n",
        "\n",
        "**Precision** tells us, when the model predicts a specific class, how often it's correct. For example, if the model has 80% precision for class 0, it means that when it predicts a protein belongs to class 0, it's right 80% of the time. This is particularly important when false positives are costly.\n",
        "\n",
        "**Recall** (also called sensitivity) shows how many proteins of a particular class the model actually found. If the recall for class 1 is 70%, it means the model correctly identified 70% of all proteins that truly belong to class 1. This matters when missing cases would be problematic.\n",
        "\n",
        "The **F1 score** balances precision and recall into a single number. It's particularly useful when you need to find a sweet spot between not missing true cases (recall) and not making false predictions (precision). An F1 score of 100% would mean perfect precision and recall.\n",
        "\n",
        "The confusion matrix provides a complete picture of the model's predictions. Each row represents the actual class, and each column shows what the model predicted. The numbers on the diagonal show correct predictions, while off-diagonal numbers show mistakes. This helps identify which classes the model commonly confuses with each other."
      ],
      "metadata": {
        "id": "Ms-WbLpEm21M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep dive on the data\n"
      ],
      "metadata": {
        "id": "eB6vX9-8oL2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're working with a network of 20 proteins, where each protein has 10 numerical features associated with it. These features are currently random numbers that simulate real protein properties - in a real biological context, they might represent characteristics like molecular weight, sequence patterns, or expression levels.\n",
        "\n",
        "The network's structure is defined by connections between proteins, which we call edges. Each edge represents a potential interaction between two proteins, created using a geometric proximity rule - proteins that are \"closer\" to each other in our simulated space are connected. This gives us a pattern of connections that mimics real protein interaction networks, though in a simplified way. We can visualize this network as a graph where each protein is a node, and lines between nodes show their interactions.\n",
        "\n",
        "Each protein in our network is also assigned to one of three classes (0, 1, or 2). These class assignments are currently random, but in a real biological context, they might represent functional categories, like whether a protein is an enzyme or a transcription factor. The distribution of these classes tells us how many proteins belong to each category.\n",
        "\n",
        "To understand the network's overall structure, we can look at metrics like the average number of interactions per protein (average degree) and network density, which tells us how many of the possible connections between proteins actually exist. These properties help us understand how tightly connected our protein network is. The network visualization shows us this structure spatially, with different colors representing the different classes, giving us a visual sense of how proteins of different types are distributed through the network.\n",
        "\n",
        "The GNN learns by combining and processing two key types of information for each protein: its own **features** and the features of proteins it **interacts** with. During each pass through the network (using the three **graph convolutional layers**), a protein's **representation** is updated by **aggregating information** from its neighbors. Think of it like each protein getting a better understanding of its role not just from its own characteristics, but also from the company it keeps in the interaction network. Each layer of the GNN allows this information to spread further through the network, so proteins eventually gain information from both **direct interaction partners** and more **distant connections**.\n",
        "\n",
        "The model's **learning process** involves finding patterns between these combined feature representations and the **class assignments**. For example, it might learn that proteins with certain feature values that interact with proteins having complementary features tend to belong to a particular class. The **weights** in the convolutional layers are adjusted through training to better capture these patterns. When the model makes a **prediction** for a protein, it's essentially saying \"based on this protein's features and the features of its interaction partners, it shows patterns similar to other proteins of class X that I've seen during training.\" The effectiveness of this learning process depends heavily on how **informative** the features are and how **meaningful** the network structure is, which is why using real biological data with actual protein properties and verified interactions would give more meaningful results than our random example."
      ],
      "metadata": {
        "id": "4Gihz9EApBWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def examine_network_data(data):\n",
        "    \"\"\"Examine and display network data features\"\"\"\n",
        "    # Print basic information\n",
        "    print(f\"Number of nodes (proteins): {data.x.shape[0]}\")\n",
        "    print(f\"Number of features per node: {data.x.shape[1]}\")\n",
        "    print(f\"Number of edges (interactions): {data.edge_index.shape[1]}\")\n",
        "    print(f\"\\nFeature matrix shape: {data.x.shape}\")\n",
        "\n",
        "    # Show example of features for first few nodes\n",
        "    print(\"\\nExample features for first 3 proteins:\")\n",
        "    for i in range(3):\n",
        "        print(f\"Protein {i} features: {data.x[i].numpy()}\")\n",
        "\n",
        "    # Show class distribution\n",
        "    unique_classes, counts = torch.unique(data.y, return_counts=True)\n",
        "    print(\"\\nClass distribution:\")\n",
        "    for class_idx, count in zip(unique_classes, counts):\n",
        "        print(f\"Class {class_idx}: {count} proteins\")\n",
        "\n",
        "    # Visualize network\n",
        "    G = nx.Graph()\n",
        "    edge_list = data.edge_index.t().numpy()\n",
        "    for edge in edge_list:\n",
        "        G.add_edge(edge[0], edge[1])\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    pos = nx.spring_layout(G)\n",
        "    nx.draw(G, pos,\n",
        "            node_color=data.y,  # Color nodes by their class\n",
        "            node_size=500,\n",
        "            cmap=plt.cm.viridis)\n",
        "    plt.title(\"Network Structure (colors represent classes)\")\n",
        "    plt.show()\n",
        "\n",
        "    return G\n",
        "\n"
      ],
      "metadata": {
        "id": "0bzsioPboUTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine the  dataset\n",
        "#data = create_example_dataset()\n",
        "G = examine_network_data(data)\n",
        "\n",
        "# Additional network analysis\n",
        "avg_degree = sum(dict(G.degree()).values()) / G.number_of_nodes()\n",
        "print(f\"\\nAverage number of interactions per protein: {avg_degree:.2f}\")\n",
        "print(f\"Network density: {nx.density(G):.3f}\")"
      ],
      "metadata": {
        "id": "WXlgzqa8oabm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Going a step further\n",
        "\n",
        "In a real-world scenario, we often face situations where not all proteins in a network have known functions or classifications. This is where Graph Neural Networks become particularly valuable. Rather than requiring complete class information for all proteins, GNNs can learn from partially labeled networks where only some proteins have known classes. The model learns patterns from the proteins with known classifications and uses these patterns, along with protein features and network structure, to predict the classes of unlabeled proteins.\n",
        "\n",
        "For example, in a network of 20 proteins, we might only know the functional classes of 17 proteins. The GNN can learn from these 17 proteins and predict the functions of the remaining 3 based on their features and their interactions with proteins of known function. This capability is especially valuable in biology since experimentally determining protein functions is time-consuming and expensive, while interaction data and protein features are often more readily available. The model essentially leverages what we already know about some proteins to make educated predictions about others.\n",
        "\n"
      ],
      "metadata": {
        "id": "iM9Wj52Qq5JL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The `create_partially_labeled_dataset()` function creates our test network with some proteins having unknown classes. It uses `random_geometric_graph` to generate the network structure and creates `num_features` random features for each protein. The key difference is that it marks some proteins as unknown by setting their class labels to `-1`. It selects which proteins to leave unlabeled using `torch.randperm` to randomly pick `num_unlabeled` proteins. Like our original dataset creation, it packages everything into a `Data` object containing the features (`x`), connections (`edge_index`), and labels (`y`).\n",
        "\n",
        "The `train_with_partial_labels()` function modifies the training process to handle unlabeled proteins. It creates a `labeled_mask` to identify which proteins have known classes, and only uses these proteins for calculating the `loss`. The function still uses an `Adam` optimizer, but now it only compares the model's predictions against the known class labels, ignoring the proteins marked with `-1`. This lets the model learn from the labeled proteins while skipping the unlabeled ones during training.\n",
        "\n",
        "The `predict_unknown_classes()` function takes our trained model and uses it to predict classes for the unlabeled proteins. It puts the model in evaluation mode with `model.eval()` and uses `torch.no_grad()` since we're not training anymore. It generates predictions for all proteins using the model, then uses an `unlabeled_mask` to find proteins with `-1` labels. For these proteins, it reports what class the model predicts based on their features and their connections to labeled proteins in the network."
      ],
      "metadata": {
        "id": "2BWFWjzmtJLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_partially_labeled_dataset(num_nodes=20, num_unlabeled=3):\n",
        "    \"\"\"Create a dataset where some proteins have unknown classes\"\"\"\n",
        "    # Create basic dataset\n",
        "    G = nx.random_geometric_graph(num_nodes, 0.3)\n",
        "    edge_index = torch.tensor([[e[0] for e in G.edges()],\n",
        "                             [e[1] for e in G.edges()]], dtype=torch.long)\n",
        "\n",
        "    # Create features\n",
        "    num_features = 10\n",
        "    x = torch.randn((num_nodes, num_features))\n",
        "\n",
        "    # Create labels, marking some as unknown (-1)\n",
        "    y = torch.randint(0, 3, (num_nodes,))\n",
        "\n",
        "    # Randomly select nodes to be unlabeled\n",
        "    unlabeled_indices = torch.randperm(num_nodes)[:num_unlabeled]\n",
        "    y[unlabeled_indices] = -1  # -1 indicates unknown class\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    return data\n",
        "\n",
        "def train_with_partial_labels(model, data):\n",
        "    \"\"\"Train model using only labeled nodes\"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Get mask for labeled nodes\n",
        "    labeled_mask = data.y != -1\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(100):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "\n",
        "        # Calculate loss only on labeled nodes\n",
        "        loss = F.nll_loss(out[labeled_mask], data.y[labeled_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "def predict_unknown_classes(model, data):\n",
        "    \"\"\"Predict classes for unlabeled nodes\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        # Show predictions for unlabeled nodes\n",
        "        unlabeled_mask = data.y == -1\n",
        "        print(\"\\nPredictions for unlabeled proteins:\")\n",
        "        for i in range(len(data.y)):\n",
        "            if unlabeled_mask[i]:\n",
        "                print(f\"Protein {i}: Predicted Class {pred[i].item()}\")"
      ],
      "metadata": {
        "id": "cf-4_YTZrIl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reate the partially labeled dataset\n",
        "data = create_partially_labeled_dataset(num_nodes=20, num_unlabeled=3)\n",
        "\n",
        "# Initialize and train the model\n",
        "# use the prevoius model\n",
        "# model = BiologyGNN(num_node_features=10, num_classes=3)\n",
        "train_with_partial_labels(model, data)\n",
        "\n",
        "# Get predictions for unlabeled proteins\n",
        "predict_unknown_classes(model, data)"
      ],
      "metadata": {
        "id": "YoeRfVUNtfta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Expression Features to the Network: TCGA Data Integration\n",
        "In order to enhance our protein-protein interaction network with meaningful biological features, we need to obtain gene expression data for each protein node. Gene expression levels from The Cancer Genome Atlas (TCGA) breast cancer dataset provide quantitative measurements of gene activity in tumor samples, which can serve as informative node features for our network. These expression values capture the abundance of each gene's transcripts, offering insights into their activity levels in the cancer context. By incorporating this high-dimensional molecular data as node features, we can generate richer embeddings that capture both the network topology and the underlying biological state of each protein, potentially improving our ability to identify cancer-related proteins through graph neural network analysis.\n"
      ],
      "metadata": {
        "id": "6Sa1lUPY8x4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore data from cBioPortal\n",
        "This code connects to cBioPortal and explores what data we can access through its API. It first lists all available methods specifically for molecular data, which we'll need for getting expression values. Then it shows all available resources in cBioPortal, giving us a complete view of what types of cancer genomics data we could potentially use."
      ],
      "metadata": {
        "id": "-MzYGQm-AQZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bravado.client import SwaggerClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize cBioPortal client\n",
        "cbioportal = SwaggerClient.from_url('https://www.cbioportal.org/api/v2/api-docs',\n",
        "    config={\"validate_requests\":False,\"validate_responses\":False,\"validate_swagger_spec\": False})\n",
        "\n",
        "# Print available methods for Molecular_Data\n",
        "print(\"Available methods for Molecular_Data:\")\n",
        "for method in dir(cbioportal.Molecular_Data):\n",
        "    if not method.startswith('_'):\n",
        "        print(method)\n",
        "\n",
        "# Let's also check what other resources are available\n",
        "print(\"\\nAvailable resources:\")\n",
        "for resource in dir(cbioportal):\n",
        "    if not resource.startswith('_'):\n",
        "        print(resource)"
      ],
      "metadata": {
        "id": "42XZHaB6_Ioq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Connect to cBioportal\n",
        "This code sets up our connection to cBioPortal's API and examines what we need to provide to fetch expression data successfully. The first part imports required libraries and initializes the API client, while the second part inspects the parameters required by the API endpoint we'll use to get molecular data.\n",
        "\n",
        "By checking these required parameters upfront, we ensure we understand exactly what information cBioPortal needs before we start fetching expression values for our network's proteins."
      ],
      "metadata": {
        "id": "w2HXXzCu_8Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bravado.client import SwaggerClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize cBioPortal client\n",
        "cbioportal = SwaggerClient.from_url('https://www.cbioportal.org/api/v2/api-docs',\n",
        "    config={\"validate_requests\":False,\"validate_responses\":False,\"validate_swagger_spec\": False})\n",
        "\n",
        "# Print the operation details to see the required parameters\n",
        "operation = cbioportal.Molecular_Data.fetchAllMolecularDataInMolecularProfileUsingPOST.operation\n",
        "print(\"Required parameters:\")\n",
        "for param in operation.params.values():\n",
        "    print(f\"- {param.name}: {param.required}\")"
      ],
      "metadata": {
        "id": "qdr6qyI-_XeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get the expression data\n",
        "This code defines and uses two key functions for fetching expression data from TCGA through cBioPortal's API. The `get_gene_ids()` function converts gene symbols to Entrez IDs, while `get_expression_data()` retrieves actual expression values for those genes. The code then processes this raw data into a clean format and generates visualizations showing correlations and distributions of expression levels across samples.\n",
        "\n",
        "This creates our base functionality for getting gene expression features that we'll later use to annotate our protein network. The example runs with just three genes (TP53, BRCA1, BRCA2) to demonstrate the workflow before we apply it to all proteins in our network."
      ],
      "metadata": {
        "id": "eb8_pX-u_eMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bravado.client import SwaggerClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize cBioPortal client\n",
        "cbioportal = SwaggerClient.from_url('https://www.cbioportal.org/api/v2/api-docs',\n",
        "    config={\"validate_requests\":False,\"validate_responses\":False,\"validate_swagger_spec\": False})\n",
        "\n",
        "def get_gene_ids(gene_symbols):\n",
        "    genes = cbioportal.Genes.fetchGenesUsingPOST(\n",
        "        geneIdType=\"HUGO_GENE_SYMBOL\",\n",
        "        geneIds=gene_symbols\n",
        "    ).result()\n",
        "\n",
        "    return {gene.hugoGeneSymbol: gene.entrezGeneId for gene in genes}\n",
        "\n",
        "def get_expression_data(genes, study_id):\n",
        "    try:\n",
        "        # Get gene IDs\n",
        "        gene_ids = get_gene_ids(genes)\n",
        "        print(f\"\\nGene IDs found: {gene_ids}\")\n",
        "\n",
        "        profile_id = 'brca_tcga_rna_seq_v2_mrna'\n",
        "\n",
        "        molecular_filter = {\n",
        "            'molecularProfileIds': [profile_id],\n",
        "            'entrezGeneIds': list(gene_ids.values())\n",
        "        }\n",
        "\n",
        "        # Fetch the data\n",
        "        expression_data = cbioportal.Molecular_Data.fetchMolecularDataInMultipleMolecularProfilesUsingPOST(\n",
        "            molecularDataMultipleStudyFilter=molecular_filter\n",
        "        ).result()\n",
        "\n",
        "        # Print sample of data\n",
        "        if expression_data:\n",
        "            print(\"\\nFirst few data points:\")\n",
        "            for i, d in enumerate(expression_data[:5]):\n",
        "                print(f\"\\nData point {i+1}:\")\n",
        "                print(f\"Sample: {d.sampleId}\")\n",
        "                print(f\"Gene: {d.entrezGeneId}\")\n",
        "                print(f\"Value: {d.value}\")\n",
        "\n",
        "        # Create DataFrame with all data points\n",
        "        raw_data = []\n",
        "        for d in expression_data:\n",
        "            if hasattr(d, 'value') and d.value is not None and d.value != 'NA':\n",
        "                raw_data.append({\n",
        "                    'sample': d.sampleId,\n",
        "                    'gene': str(d.entrezGeneId),\n",
        "                    'value': float(d.value)\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(raw_data)\n",
        "\n",
        "        # Print data shape before pivot\n",
        "        print(f\"\\nRaw data shape: {df.shape}\")\n",
        "        print(\"\\nSample counts per gene:\")\n",
        "        print(df.groupby('gene').size())\n",
        "\n",
        "        # Create mapping of Entrez IDs to gene symbols\n",
        "        entrez_to_symbol = {str(v): k for k, v in gene_ids.items()}\n",
        "        df['gene'] = df['gene'].map(entrez_to_symbol)\n",
        "\n",
        "        # Check for duplicates\n",
        "        duplicates = df.duplicated(subset=['sample', 'gene'], keep=False)\n",
        "        if duplicates.any():\n",
        "            print(\"\\nFound duplicate entries:\")\n",
        "            print(df[duplicates].sort_values(['sample', 'gene']))\n",
        "\n",
        "            # Handle duplicates by taking the mean\n",
        "            df = df.groupby(['sample', 'gene'])['value'].mean().reset_index()\n",
        "\n",
        "        # Create pivot table\n",
        "        pivot_df = df.pivot(index='sample', columns='gene', values='value')\n",
        "\n",
        "        print(f\"\\nFinal data shape: {pivot_df.shape}\")\n",
        "        print(\"\\nGenes in dataset:\")\n",
        "        for gene in pivot_df.columns:\n",
        "            print(f\"- {gene}\")\n",
        "\n",
        "        return pivot_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data: {str(e)}\")\n",
        "        print(\"\\nRequest details:\")\n",
        "        print(f\"Profile ID: {profile_id}\")\n",
        "        print(f\"Genes: {genes}\")\n",
        "        print(f\"Gene IDs: {gene_ids}\")\n",
        "        return None\n",
        "\n",
        "# Get your known cancer genes\n",
        "cancer_genes = ['TP53', 'BRCA1', 'BRCA2']\n",
        "\n",
        "# Get expression data\n",
        "expr_data = get_expression_data(cancer_genes, 'brca_tcga')\n",
        "\n",
        "if expr_data is not None:\n",
        "    # Calculate correlations\n",
        "    correlations = expr_data.corr()\n",
        "    print(\"\\nExpression correlations between cancer genes:\")\n",
        "    print(correlations)\n",
        "\n",
        "    # Add some basic statistics\n",
        "    print(\"\\nBasic statistics for each gene:\")\n",
        "    print(expr_data.describe())\n",
        "\n",
        "    # Visualizations\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Correlation heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(correlations, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title('Gene Expression Correlations')\n",
        "    plt.show()\n",
        "\n",
        "    # Expression distributions\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    expr_data.boxplot()\n",
        "    plt.title('Expression Distribution by Gene')\n",
        "    plt.ylabel('Expression Level')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lFHyNTqyAoDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####\n",
        "\n"
      ],
      "metadata": {
        "id": "Z13pmkuZBHbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bravado.client import SwaggerClient\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize cBioPortal client\n",
        "cbioportal = SwaggerClient.from_url('https://www.cbioportal.org/api/v2/api-docs',\n",
        "    config={\"validate_requests\":False,\"validate_responses\":False,\"validate_swagger_spec\": False})\n",
        "\n",
        "def get_gene_ids(gene_symbols):\n",
        "    genes = cbioportal.Genes.fetchGenesUsingPOST(\n",
        "        geneIdType=\"HUGO_GENE_SYMBOL\",\n",
        "        geneIds=gene_symbols\n",
        "    ).result()\n",
        "    return {gene.hugoGeneSymbol: gene.entrezGeneId for gene in genes}\n",
        "\n",
        "def get_normalized_expression(genes, study_id):\n",
        "    try:\n",
        "        # Get gene IDs\n",
        "        gene_ids = get_gene_ids(genes)\n",
        "\n",
        "        # Use the z-score profile instead of raw counts\n",
        "        profile_id = 'brca_tcga_rna_seq_v2_mrna_median_Zscores'\n",
        "\n",
        "        molecular_filter = {\n",
        "            'molecularProfileIds': [profile_id],\n",
        "            'entrezGeneIds': list(gene_ids.values())\n",
        "        }\n",
        "\n",
        "        # Fetch the data\n",
        "        expression_data = cbioportal.Molecular_Data.fetchMolecularDataInMultipleMolecularProfilesUsingPOST(\n",
        "            molecularDataMultipleStudyFilter=molecular_filter\n",
        "        ).result()\n",
        "\n",
        "        # Create DataFrame\n",
        "        raw_data = []\n",
        "        for d in expression_data:\n",
        "            if hasattr(d, 'value') and d.value is not None and d.value != 'NA':\n",
        "                raw_data.append({\n",
        "                    'sample': d.sampleId,\n",
        "                    'gene': str(d.entrezGeneId),\n",
        "                    'zscore': float(d.value)\n",
        "                })\n",
        "\n",
        "        df = pd.DataFrame(raw_data)\n",
        "\n",
        "        # Map Entrez IDs to gene symbols\n",
        "        entrez_to_symbol = {str(v): k for k, v in gene_ids.items()}\n",
        "        df['gene'] = df['gene'].map(entrez_to_symbol)\n",
        "\n",
        "        # Handle any duplicates by taking mean\n",
        "        df = df.groupby(['sample', 'gene'])['zscore'].mean().reset_index()\n",
        "\n",
        "        # Create pivot table\n",
        "        pivot_df = df.pivot(index='sample', columns='gene', values='zscore')\n",
        "\n",
        "        return pivot_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Get expression data for cancer genes\n",
        "cancer_genes = ['TP53', 'BRCA1', 'BRCA2']\n",
        "expr_data = get_normalized_expression(cancer_genes, 'brca_tcga')\n",
        "\n",
        "if expr_data is not None:\n",
        "    # Display first few rows\n",
        "    print(\"\\nFirst 10 samples (z-scores):\")\n",
        "    print(expr_data.head(10))\n",
        "\n",
        "    # Save to CSV\n",
        "    expr_data.to_csv('brca_gene_expression_zscores.csv')\n",
        "    print(\"\\nFull data saved to 'brca_gene_expression_zscores.csv'\")\n",
        "\n",
        "    # Basic statistics\n",
        "    print(\"\\nSummary statistics:\")\n",
        "    print(expr_data.describe())\n",
        "\n",
        "    # Number of samples with altered expression (|z-score| > 2)\n",
        "    altered = (expr_data.abs() > 2).sum()\n",
        "    print(\"\\nNumber of samples with altered expression (|z-score| > 2):\")\n",
        "    for gene in altered.index:\n",
        "        print(f\"{gene}: {altered[gene]} samples\")"
      ],
      "metadata": {
        "id": "b9Pad--tBND7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}